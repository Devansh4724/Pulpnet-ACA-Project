# Webscraper AI
### It is a Llama3.1 based web scraping agent capable of extracting information from the website whose URL is entered by the user. Once, the information is extracted after entering the URL, the user may type in their query in the designated box and the output will be generated by the LLM based on information extracted.

## How to run?
### The submitted folder has the following files:
1. [main.py](Webscraper%20AI/main.py)
2. [parse.py](Webscraper%20AI/parse.py)
3. [scraper.py](Webscraper%20AI/scraper.py)
4. [processed_data.txt](Webscraper%20AI/processed_data.txt)
5. [Demo of working model](Webscraper%20AI/05.07.2025_19.19.19_REC.mp4)

### Follow the steps below:
### Note: If using for the first time, perform steps 1-8. If not, you can directly jump to step 6.
1. Download the above files on your local computer in a new folder.
2. Ensure that the following libraries are installed on your system:  
   i. streamlit  
   ii. langchain_ollama  
   iii. langchain_core  
   iv. selenium  
   v. time  
   vi. bs4  
   If not, install using Command Prompt.
3. Install Ollama from [here](https://ollama.com/download/windows).
4. Install the webdriver according to the version of your Google Chrome webbrowser from [here](https://googlechromelabs.github.io/chrome-for-testing/) and save it     in the following path:
   ```bash
   C:\Program Files (x86)\chromedriver.exe
   ```
   If saving elsewhere, change the driver path in [scraper.py](Webscraper%20AI/scraper.py)
5. In the Command Prompt, write the following bash command to install Llama3.1 on your PC.
   ```bash
   ollama pull llama3.1
   ```
6. Open the file [main.py](Webscraper%20AI/main.py) in a text editor/IDLE and type the following command in the terminal/Command Prompt(which is opened in the same folder where main.py is kept)    
   ```bash
   streamlit run main.py
   ```
7. A new window of Streamlit App will open on the web-browser. In the designated boxes, type in the URL of the website you want to scrape and click on "Scrape Website". Once, the scraping is complete, enter your query in the designated box and click "Parse Content". After sometime, output will be generated.
8. To reuse the application, refresh the browser window and repeat steps 5 and 6.

Thank you for checking out this project! We hope it proves useful in your work. If you have any questions or suggestions, please open an issue or submit a pull request.
Feel free to connect with us via email at devanshc24@iitk.ac.in.

### Name: Devansh Chaturvedi
### Roll No: 240340
### ACA Project: Pulpnet
